{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636796e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from interface.load_data import (\n",
    "    load_data_fault_free_test,\n",
    "    load_data_fault_free_train,\n",
    "    load_data_faulty_test,\n",
    "    load_data_faulty_train,\n",
    "    load_data_fault_free_test_select\n",
    "\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87a754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6e3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, Input, layers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c76450a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000, 55)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faulty_train = load_data_faulty_train()\n",
    "faulty_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134cb6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = [i*10 for i in range(int(faulty_train.shape[0]/10))]\n",
    "\n",
    "faulty_train_w = faulty_train.iloc[mask]\n",
    "faulty_train_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56489dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list = [slice() for i in range]\n",
    "#np.r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a210c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_slice = [slice(i * 50, (i+1) * 50) for i in range(1000)]\n",
    "#list_fault = [[list_slice[0]...list_slice[49], []]\n",
    "list_fault = [[list_slice[i+j*50] for i in range(50)] for j in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_faults(len_sample=500):\n",
    "    list_slice = [slice(i * len_sample, (i+1) * len_sample) for i in range(len_sample*20)]\n",
    "    list_fault = [[list_slice[i+j*len_sample] for i in range(50)] for j in range(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e0baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = faulty_train.drop(columns=['faultNumber', 'simulationRun', 'sample'])\n",
    "y = faulty_train.faultNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f1d30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w = faulty_train_w.drop(columns=['faultNumber', 'simulationRun', 'sample'])\n",
    "y_w = faulty_train_w.faultNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "598ff8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat_select = faulty_train_w[['xmeas_6', 'xmeas_18', 'xmeas_7', 'xmeas_13']]\n",
    "y_feat_select = faulty_train_w.faultNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a0bec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_w, y_w, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1714ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b43e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulation = 500\n",
    "len_simulation = 10000\n",
    "n_per_sample = 50\n",
    "n_fault = 20\n",
    "n_features = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b9b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train_scaled.values.reshape(round(len_simulation*0.7), n_per_sample, n_features)\n",
    "y_train_reshaped = y_train.values.reshape(round(len_simulation*0.7), n_per_sample)[:, 0]\n",
    "\n",
    "X_test_reshaped = X_test_scaled.values.reshape(round(len_simulation*0.3), n_per_sample, n_features)\n",
    "y_test_reshaped = y_test.values.reshape(round(len_simulation*0.3), n_per_sample)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf4f818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 50, 52)\n",
      "(7000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_reshaped.shape)\n",
    "print(y_train_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd2b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape globale : (500000, 52)\n",
      "\n",
      "--- Fold 1 ---\n",
      "Warning: Trimming 35 rows from training set to ensure complete sequences.\n",
      "Warning: Trimming 33 rows from test set to ensure complete sequences.\n",
      "Train shape: (1666, 50, 52)\n",
      "Test shape:  (1666, 50, 52)\n",
      "\n",
      "--- Fold 2 ---\n",
      "Warning: Trimming 18 rows from training set to ensure complete sequences.\n",
      "Warning: Trimming 33 rows from test set to ensure complete sequences.\n",
      "Train shape: (3333, 50, 52)\n",
      "Test shape:  (1666, 50, 52)\n",
      "\n",
      "--- Fold 3 ---\n",
      "Warning: Trimming 1 rows from training set to ensure complete sequences.\n",
      "Warning: Trimming 33 rows from test set to ensure complete sequences.\n",
      "Train shape: (5000, 50, 52)\n",
      "Test shape:  (1666, 50, 52)\n",
      "\n",
      "--- Fold 4 ---\n",
      "Warning: Trimming 34 rows from training set to ensure complete sequences.\n",
      "Warning: Trimming 33 rows from test set to ensure complete sequences.\n",
      "Train shape: (6666, 50, 52)\n",
      "Test shape:  (1666, 50, 52)\n",
      "\n",
      "--- Fold 5 ---\n",
      "Warning: Trimming 17 rows from training set to ensure complete sequences.\n",
      "Warning: Trimming 33 rows from test set to ensure complete sequences.\n",
      "Train shape: (8333, 50, 52)\n",
      "Test shape:  (1666, 50, 52)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# 2. Préparation de la validation croisée\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(f\"Shape globale : {X_w.shape}\")\n",
    "\n",
    "# 3. Boucle d'entraînement\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X_w)):\n",
    "    print(f\"\\n--- Fold {fold+1} ---\")\n",
    "\n",
    "    # A. Découpage\n",
    "    X_train_2, X_test_2 = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_2, y_test_2 = X_w.iloc[train_index], y_w.iloc[test_index]\n",
    "\n",
    "    # B. Normalisation (L'étape critique avec 52 features)\n",
    "    # On doit aplatir les données pour le scaler : (N_seq * Time, Features)\n",
    "    # Cela permet de normaliser chaque feature indépendamment du temps\n",
    "\n",
    "    num_features = X_train_2.shape[1]        # Number of features\n",
    "    timesteps_per_sequence = 50 # Assuming 500 timesteps per sequence. PLEASE VERIFY.\n",
    "\n",
    "    # Ensure training set has complete sequences by trimming excess rows\n",
    "    num_rows_train_fold = X_train_2.shape[0]\n",
    "    remainder_train = num_rows_train_fold % timesteps_per_sequence\n",
    "    if remainder_train != 0:\n",
    "        print(f\"Warning: Trimming {remainder_train} rows from training set to ensure complete sequences.\")\n",
    "        X_train_2 = X_train_2.iloc[:-remainder_train]\n",
    "        y_train_2 = y_train_2.iloc[:-remainder_train]\n",
    "        num_rows_train_fold = X_train_2.shape[0]\n",
    "    num_sequences_train_fold = num_rows_train_fold // timesteps_per_sequence\n",
    "\n",
    "    # Ensure test set has complete sequences by trimming excess rows\n",
    "    num_rows_test_fold = X_test_2.shape[0]\n",
    "    remainder_test = num_rows_test_fold % timesteps_per_sequence\n",
    "    if remainder_test != 0:\n",
    "        print(f\"Warning: Trimming {remainder_test} rows from test set to ensure complete sequences.\")\n",
    "        X_test_2 = X_test_2.iloc[:-remainder_test]\n",
    "        y_test_2 = y_test_2.iloc[:-remainder_test]\n",
    "        num_rows_test_fold = X_test_2.shape[0]\n",
    "    num_sequences_test_fold = num_rows_test_fold // timesteps_per_sequence\n",
    "\n",
    "    # Convert DataFrames to NumPy arrays before scaling and reshaping\n",
    "    X_train_np = X_train_2.values\n",
    "    X_test_np = X_test_2.values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # FIT only on TRAIN! The data is already in 2D (num_rows, num_features) for scaling.\n",
    "    X_train_scaled_2d = scaler.fit_transform(X_train_np)\n",
    "    # TRANSFORM on TEST (using stats from train)\n",
    "    X_test_scaled_2d = scaler.transform(X_test_np)\n",
    "\n",
    "    # Return to 3D for the RNN: (num_sequences, timesteps_per_sequence, num_features)\n",
    "    X_train_final = X_train_scaled_2d.reshape(num_sequences_train_fold, timesteps_per_sequence, num_features)\n",
    "    X_test_final = X_test_scaled_2d.reshape(num_sequences_test_fold, timesteps_per_sequence, num_features)\n",
    "\n",
    "    print(f\"Train shape: {X_train_final.shape}\")\n",
    "    print(f\"Test shape:  {X_test_final.shape}\")\n",
    "\n",
    "    # C. Entraînement du modèle (Exemple Keras/TensorFlow)\n",
    "    # model = create_rnn_model(input_shape=(500, 52), num_classes=20)\n",
    "    # model.fit(X_train_final, y_train, validation_data=(X_test_final, y_test)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbf4f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(50, 52)),\n",
    "\n",
    "    layers.Conv1D(64, kernel_size=7, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    layers.Conv1D(128, kernel_size=5, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    layers.Conv1D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    layers.Conv1D(512, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(21, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01f416f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a430702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4166670    14\n",
       "4166680    14\n",
       "4166690    14\n",
       "4166700    14\n",
       "4166710    14\n",
       "           ..\n",
       "4999620    20\n",
       "4999630    20\n",
       "4999640    20\n",
       "4999650    20\n",
       "4999660    20\n",
       "Name: faultNumber, Length: 83300, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "565566fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 52), output.shape=(None, 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)]\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/monitor-reactor/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/monitor-reactor/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:734\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    729\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    732\u001b[0m     )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must have rank (ndim) `target.ndim - 1`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m     )\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 52), output.shape=(None, 20)"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(patience=15)]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b85b645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2297 - loss: 4.5222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.522157669067383, 0.22966666519641876]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reshaped, y_test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb6239f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_pred_pross = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30452f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.84      0.76       159\n",
      "           2       0.82      0.88      0.85       155\n",
      "           3       0.08      0.06      0.07       166\n",
      "           4       0.07      0.06      0.06       142\n",
      "           5       0.08      0.09      0.08       149\n",
      "           6       0.91      0.89      0.90       141\n",
      "           7       0.19      0.12      0.15       160\n",
      "           8       0.14      0.12      0.13       145\n",
      "           9       0.04      0.05      0.05       146\n",
      "          10       0.09      0.05      0.06       159\n",
      "          11       0.07      0.10      0.08       142\n",
      "          12       0.13      0.15      0.14       144\n",
      "          13       0.18      0.18      0.18       154\n",
      "          14       0.07      0.07      0.07       153\n",
      "          15       0.07      0.03      0.05       151\n",
      "          16       0.09      0.11      0.10       157\n",
      "          17       0.11      0.13      0.12       147\n",
      "          18       0.58      0.47      0.52       153\n",
      "          19       0.05      0.06      0.06       134\n",
      "          20       0.08      0.10      0.09       143\n",
      "\n",
      "    accuracy                           0.23      3000\n",
      "   macro avg       0.23      0.23      0.23      3000\n",
      "weighted avg       0.23      0.23      0.23      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test_reshaped, y_pred_pross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fea1e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.68535075e-18 9.58688106e-05 2.79025926e-06 1.25076156e-03\n",
      "  2.33597038e-05 9.89856243e-01 5.38902183e-04 9.33874981e-05\n",
      "  3.51306517e-04 2.44923052e-04 2.22030957e-03 6.44183252e-04\n",
      "  1.69263699e-03 1.01384567e-03 1.17066320e-05 3.17437400e-04\n",
      "  4.35826310e-04 2.62182846e-04 1.15579656e-04 5.47922740e-04\n",
      "  2.80846405e-04]]\n",
      "[ 3 10 10 ... 17  3  2]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0efe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_w.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monitor-reactor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
